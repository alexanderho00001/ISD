{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to EZ Survival Project Documentation! TA Amir Salimi Team Advi Islam Alex Ho Excel Ojeifo Hoang Nguyen Selena Chainani Shahmeer Rahman Yaatheshini Ashok Kumar Clients Department of Computing Science Russ Greiner Nasimeh Asgarian","title":"Home"},{"location":"#welcome-to-ez-survival-project-documentation","text":"","title":"Welcome to EZ Survival Project Documentation!"},{"location":"#ta","text":"Amir Salimi","title":"TA"},{"location":"#team","text":"Advi Islam Alex Ho Excel Ojeifo Hoang Nguyen Selena Chainani Shahmeer Rahman Yaatheshini Ashok Kumar","title":"Team"},{"location":"#clients","text":"Department of Computing Science Russ Greiner Nasimeh Asgarian","title":"Clients"},{"location":"design/","text":"Software Design This page includes a short description of the overall architecture style of the system, its high-level system components, and their logical (what data they exchange) and control (how they invoke each other) dependencies. High-level Architecture This is a short description of the architecture. UML Class Diagram This is a short description of logical entities of the domain in a UML diagram. Sequence Diagram Multiple sequence diagrams depicting the most important scenarios. Wireframes Looking at the wireframes, anyone should be able to get an idea of what will be developed. Test your wireframes with your client, encourage them to give feedback. For a clearer look, go here . Tech Stack (Everyone) List the possible tech stack you will be using. Include links and descriptions of any libraries, frameworks, and tools you will be using. Backend Ruby On Rails MySQL Look up C++ / R as applicable (not quite writing the code but may have to parse it as we are working with models.) Frontend React + Typescript Vite React Router Tailwind CSS Zustand","title":"Software Design"},{"location":"design/#software-design","text":"This page includes a short description of the overall architecture style of the system, its high-level system components, and their logical (what data they exchange) and control (how they invoke each other) dependencies.","title":"Software Design"},{"location":"design/#high-level-architecture","text":"This is a short description of the architecture.","title":"High-level Architecture"},{"location":"design/#uml-class-diagram","text":"This is a short description of logical entities of the domain in a UML diagram.","title":"UML Class Diagram"},{"location":"design/#sequence-diagram","text":"Multiple sequence diagrams depicting the most important scenarios.","title":"Sequence Diagram"},{"location":"design/#wireframes","text":"Looking at the wireframes, anyone should be able to get an idea of what will be developed. Test your wireframes with your client, encourage them to give feedback. For a clearer look, go here .","title":"Wireframes"},{"location":"design/#tech-stack-everyone","text":"List the possible tech stack you will be using. Include links and descriptions of any libraries, frameworks, and tools you will be using.","title":"Tech Stack (Everyone)"},{"location":"design/#backend","text":"Ruby On Rails MySQL Look up C++ / R as applicable (not quite writing the code but may have to parse it as we are working with models.)","title":"Backend"},{"location":"design/#frontend","text":"React + Typescript Vite React Router Tailwind CSS Zustand","title":"Frontend"},{"location":"management/","text":"Project Management Story Map Should include all user stories. You should start the document with a storymap. Include all five sprints. Don't forget to indicate estimation of each user story (in story points). Project Plan Meeting Minutes are here Sprint 1 Due date: 28 Sept 2025 Initial MkDocs Setup and Sections Drafted (Yaatheshini: Sept 19) Project Requirements Document Update (Selena: Sept 21, Yaatheshini: Sept 22) Completed Software Design Document - High-level Architecture (Excel, Advi) Due: Wednesday, Sept 24 **Completed** - UML Class Diagram (Yaatheshini, Alex, Shahmeer) Due: Wednesday, Sept 24 **Completed** - Sequence Diagrams Dependent on UML Class Diagram - will revisit Wednesday - revisited: (Yaatheshini, Advi) **Completed** - Wireframes (Selena, Hoang) Due: Wednesday, Sept 24 **Completed** - Tech Stack Discuss further with TA on Wednesday - discussed; also discussed further within team **Completed**; consensus reached for now Project Management Document (Selena: Sept 21, Yaatheshini: Sept 22) - User Issues Added on GitHub (Yaatheshini: Sept 22) - Acceptance Tests added on wesbite (Alex) - User Issues and Stories fleshed out on both website / GitHub (Selena) - Story Points and tags added (Selena, Advi) - Assignees added **Completed** - Storymap (Hoang) Discuss storymap structure and trajectory on Wednesday - Planned it out (Hoang) **Completed** View more details in here . - Project Plan (Selena: Sept 21) **Completed** Teamwork Document (Yaatheshini, Selena) Pending - Team Canvas (Everyone) **Completed** - Belbin Roles Everyone has been asked to send in their Belbin roles + preferences on the #teamwork-doc channel on Discord. Discuss other specifics on Wednesday, Sept 24. Pending discussion with TA. - discussed, asked about how preference works **Completed** First Draft of All Deliverables Due: Thursday, Sept 25 Actually Finished: Saturday, Sept 27 Confirm Submission: Sunday, Sept 28 Sprint 2 Due date: 12 Oct 2025 List of user stories to be completed User Story Number Description Story Points Assignee(s) US 1.1 User Logging In / Out 3 Yaatheshini, Advi US 1.1.1 Change Password 1 Alex US 1.2 Superuser / Admin Logging In / Out 1 Hoang, Excel US 1.3 Logged-In User Dashboard 3 Advi, Selena US 1.3.1 Upload a Dataset 3 Yaatheshini, Excel US 1.3.3 Predictor Privacy 2 Advi, Shahmeer US 1.3.4 Create a Predictor 3 Selena, Excel, Alex US 1.3.5 Edit a Predictor 3 Shahmeer, Yaatheshini US 1.3.6 Delete a Predictor 1 Advi, Yaatheshini US 1.3.7 Pin Predictors 3 Advi, Selena US 1.4.1 Display Predictors 2 Advi, Selena US 1.5 Superuser / Admin Access (Panel Set-Up) 8 Advi, Selena, Alex, Yaatheshini, Hoang US 1.7 Landing Page 2 Excel US 1.8 About Page 2 Shahmeer US 4.1.1 Instructions Page 1 Alex, Yaatheshini US 4.1.2 Hover Over Button / Tab for Info 2 Selena US 6.1 Tests for Sprint 2 3 Shahmeer, Alex Estimated sprint velocity : 43 Initial Check-In - October 5th Due (for Review) - (tentative) October 9th Due - (tentative) October 11th Sprint 3 Due date: 26 Oct 2025 List of user stories to be completed User Story Number Description Story Points Assignee(s) US 1.3.2 Upload Formatted Datasets 3 TBD US 1.3.3.1 Share Private Predictors 5 TBD US 1.4.2 Search for a Dataset / Predictor 3 TBD US 1.4.3 Filter Predictors By Public / Private Access 1 TBD US 1.6.1 Create Folders 2 TBD US 1.6.2 Delete Folders 1 TBD US 1.6.3 Toggle Folder Visibility 5 TBD US 1.6.4 Move Predictors Between Folders 5 TBD US 2.1 Identify an accessible dataset, a specific learning tool, and a specification of that learner's hyperparameter 8 TBD US 2.1.2 Save Predictors After Runs 3 TBD US 2.1.3 Re-Train Predictors 2 TBD US 2.1.3.1 Search for Features 2 TBD US 2.1.3.2 Select and Deselect All Features 2 TBD US 2.1.3.3 Paginate Features 2 TBD US 2.2 Implement Learning Tools 5 TBD US 2.3 Cross-Validation Evaluation of Predictor 8 TBD US 4.2 Guided Tour / Demo Implementation 3 TBD Estimated sprint velocity : 60 Initial Check-In - October 19th Due (for Review) - (tentative) October 23th Due - (tentative) October 25th Sprint 4 Due date: 9 Nov 2025 List of user stories to be completed User Story Number Description Story Points Assignee(s) US 3.1 Run Predictors on Unlabeled Data 2 TBD US 3.3 Quality Evaluation of Predictors 3 TBD US 3.4 Dataset Metrics / Analysis 3 TBD US 3.5 Print Results 2 TBD US 3.6 Download Results 2 TBD US 3.7 Superuser-Specific Analysis Tools 5 TBD Estimated sprint velocity : 17 Initial Check-In - November 2nd Due (for Review) - (tentative) November 6th Due - (tentative) November 8th Sprint 5 Due date: 30 Nov 2025 List of user stories to be completed User Story Number Description Story Points Assignee(s) US 1.3.3.2 (Optional) - Manage User Permissions on Private Predictor 5 TBD US 1.3.8 (Optional) - Save My Draft Predictors 3 TBD US 5.1 (Optional) - PSSP Package Download 8 TBD US 5.2 (Optional) - Handle Censored Data 8 TBD Estimated sprint velocity : 24 Initial Check-In - November 23th Due (for Review) - (tentative) November 27th Due - (tentative) November 29th","title":"Project Management"},{"location":"management/#project-management","text":"","title":"Project Management"},{"location":"management/#story-map","text":"Should include all user stories. You should start the document with a storymap. Include all five sprints. Don't forget to indicate estimation of each user story (in story points).","title":"Story Map"},{"location":"management/#project-plan","text":"Meeting Minutes are here","title":"Project Plan"},{"location":"management/#sprint-1","text":"Due date: 28 Sept 2025","title":"Sprint 1"},{"location":"management/#initial-mkdocs-setup-and-sections-drafted-yaatheshini-sept-19","text":"","title":"Initial MkDocs Setup and Sections Drafted (Yaatheshini: Sept 19)"},{"location":"management/#project-requirements-document-update-selena-sept-21-yaatheshini-sept-22","text":"Completed","title":"Project Requirements Document Update (Selena: Sept 21, Yaatheshini: Sept 22)"},{"location":"management/#software-design-document","text":"- High-level Architecture (Excel, Advi) Due: Wednesday, Sept 24 **Completed** - UML Class Diagram (Yaatheshini, Alex, Shahmeer) Due: Wednesday, Sept 24 **Completed** - Sequence Diagrams Dependent on UML Class Diagram - will revisit Wednesday - revisited: (Yaatheshini, Advi) **Completed** - Wireframes (Selena, Hoang) Due: Wednesday, Sept 24 **Completed** - Tech Stack Discuss further with TA on Wednesday - discussed; also discussed further within team **Completed**; consensus reached for now","title":"Software Design Document"},{"location":"management/#project-management-document-selena-sept-21-yaatheshini-sept-22","text":"- User Issues Added on GitHub (Yaatheshini: Sept 22) - Acceptance Tests added on wesbite (Alex) - User Issues and Stories fleshed out on both website / GitHub (Selena) - Story Points and tags added (Selena, Advi) - Assignees added **Completed** - Storymap (Hoang) Discuss storymap structure and trajectory on Wednesday - Planned it out (Hoang) **Completed** View more details in here . - Project Plan (Selena: Sept 21) **Completed**","title":"Project Management Document (Selena: Sept 21, Yaatheshini: Sept 22)"},{"location":"management/#teamwork-document-yaatheshini-selena-pending","text":"- Team Canvas (Everyone) **Completed** - Belbin Roles Everyone has been asked to send in their Belbin roles + preferences on the #teamwork-doc channel on Discord. Discuss other specifics on Wednesday, Sept 24. Pending discussion with TA. - discussed, asked about how preference works **Completed**","title":"Teamwork Document (Yaatheshini, Selena) Pending"},{"location":"management/#first-draft-of-all-deliverables-due-thursday-sept-25","text":"","title":"First Draft of All Deliverables Due: Thursday, Sept 25"},{"location":"management/#actually-finished-saturday-sept-27","text":"","title":"Actually Finished: Saturday, Sept 27"},{"location":"management/#confirm-submission-sunday-sept-28","text":"","title":"Confirm Submission: Sunday, Sept 28"},{"location":"management/#sprint-2","text":"Due date: 12 Oct 2025","title":"Sprint 2"},{"location":"management/#list-of-user-stories-to-be-completed","text":"User Story Number Description Story Points Assignee(s) US 1.1 User Logging In / Out 3 Yaatheshini, Advi US 1.1.1 Change Password 1 Alex US 1.2 Superuser / Admin Logging In / Out 1 Hoang, Excel US 1.3 Logged-In User Dashboard 3 Advi, Selena US 1.3.1 Upload a Dataset 3 Yaatheshini, Excel US 1.3.3 Predictor Privacy 2 Advi, Shahmeer US 1.3.4 Create a Predictor 3 Selena, Excel, Alex US 1.3.5 Edit a Predictor 3 Shahmeer, Yaatheshini US 1.3.6 Delete a Predictor 1 Advi, Yaatheshini US 1.3.7 Pin Predictors 3 Advi, Selena US 1.4.1 Display Predictors 2 Advi, Selena US 1.5 Superuser / Admin Access (Panel Set-Up) 8 Advi, Selena, Alex, Yaatheshini, Hoang US 1.7 Landing Page 2 Excel US 1.8 About Page 2 Shahmeer US 4.1.1 Instructions Page 1 Alex, Yaatheshini US 4.1.2 Hover Over Button / Tab for Info 2 Selena US 6.1 Tests for Sprint 2 3 Shahmeer, Alex Estimated sprint velocity : 43 Initial Check-In - October 5th Due (for Review) - (tentative) October 9th Due - (tentative) October 11th","title":"List of user stories to be completed"},{"location":"management/#sprint-3","text":"Due date: 26 Oct 2025","title":"Sprint 3"},{"location":"management/#list-of-user-stories-to-be-completed_1","text":"User Story Number Description Story Points Assignee(s) US 1.3.2 Upload Formatted Datasets 3 TBD US 1.3.3.1 Share Private Predictors 5 TBD US 1.4.2 Search for a Dataset / Predictor 3 TBD US 1.4.3 Filter Predictors By Public / Private Access 1 TBD US 1.6.1 Create Folders 2 TBD US 1.6.2 Delete Folders 1 TBD US 1.6.3 Toggle Folder Visibility 5 TBD US 1.6.4 Move Predictors Between Folders 5 TBD US 2.1 Identify an accessible dataset, a specific learning tool, and a specification of that learner's hyperparameter 8 TBD US 2.1.2 Save Predictors After Runs 3 TBD US 2.1.3 Re-Train Predictors 2 TBD US 2.1.3.1 Search for Features 2 TBD US 2.1.3.2 Select and Deselect All Features 2 TBD US 2.1.3.3 Paginate Features 2 TBD US 2.2 Implement Learning Tools 5 TBD US 2.3 Cross-Validation Evaluation of Predictor 8 TBD US 4.2 Guided Tour / Demo Implementation 3 TBD Estimated sprint velocity : 60 Initial Check-In - October 19th Due (for Review) - (tentative) October 23th Due - (tentative) October 25th","title":"List of user stories to be completed"},{"location":"management/#sprint-4","text":"Due date: 9 Nov 2025","title":"Sprint 4"},{"location":"management/#list-of-user-stories-to-be-completed_2","text":"User Story Number Description Story Points Assignee(s) US 3.1 Run Predictors on Unlabeled Data 2 TBD US 3.3 Quality Evaluation of Predictors 3 TBD US 3.4 Dataset Metrics / Analysis 3 TBD US 3.5 Print Results 2 TBD US 3.6 Download Results 2 TBD US 3.7 Superuser-Specific Analysis Tools 5 TBD Estimated sprint velocity : 17 Initial Check-In - November 2nd Due (for Review) - (tentative) November 6th Due - (tentative) November 8th","title":"List of user stories to be completed"},{"location":"management/#sprint-5","text":"Due date: 30 Nov 2025","title":"Sprint 5"},{"location":"management/#list-of-user-stories-to-be-completed_3","text":"User Story Number Description Story Points Assignee(s) US 1.3.3.2 (Optional) - Manage User Permissions on Private Predictor 5 TBD US 1.3.8 (Optional) - Save My Draft Predictors 3 TBD US 5.1 (Optional) - PSSP Package Download 8 TBD US 5.2 (Optional) - Handle Censored Data 8 TBD Estimated sprint velocity : 24 Initial Check-In - November 23th Due (for Review) - (tentative) November 27th Due - (tentative) November 29th","title":"List of user stories to be completed"},{"location":"requirements/","text":"Project Requirements Executive Summary EZ Survival Prediction is best described as a brownfield project with large patches of green. To be precise, it is based on the existing PSSP site. The current website is 7\u20138 years old, slow, and difficult to navigate, and the existing tools for learning and evaluating ISD models are slow, cumbersome and lack extensive features. Our product will let machine learning researchers and other practitioners in the relevant fields upload survival datasets, train survival models with adjustable parameters using various learning tools, evaluate the models using various metrics and run predictions on new unlabeled instances, and obtain Individual Survival Distributions (ISDs) for new instances. The system will also allow the secure storage, search, and evaluation of datasets and models. Users will be able to: Upload a survival dataset (spreadsheet format) and train a survival model with adjustable parameters. View cross-validation and other evaluation metrics for the learned model. Run the trained model on new, unlabeled instances to obtain ISD predictions (time-probability distributions). Our target users include medical researchers and clinicians, engineers, finance managers, and insurance agents who are familiar with spreadsheets but not with programming. The system is web-based, initially running in a browser (focus on Chrome). If time permits, it may also be packaged as an Excel/G-Sheet/SPSS add-on. Project Glossary ISD - Individual Survival Distributions User - A non-logged-in user. Can view public datasets. LIU - A logged-in user. Can view all public datasets, and any private datasets they are permitted to view. Can also upload new datasets and train models. Superuser - Admin with permission to view high-level statistics across all datasets/models (public and private). Uncensored Data - Survival time that fully captures the patient\u2019s entire lifespan (i.e., complete data). Censored Data - Incomplete survival time information, representing only a lower bound of a patient\u2019s lifespan. Prevalent across datasets and an issue addressed by the client's research. KM Curve (Kaplan-Meier) - A standard survival function estimate used for comparisons. User Stories User stories must be prioritized using the MoSCoW method. 1. User Access US 1.1 - User Logging in / Out SP: 3 As a user, I want to log in and log out using my Google account, so that I can save my datasets and predictions. Acceptance Tests 1. User can click the button \"Sign In With Google Account\", or alternatively enter a gmail address, followed by a password 2. User is prompted with a pop-up to choose their Google Account 3. User cannot sign up without a Google Account; the entered email is flagged if it is not a gmail account 4. User cannot enter a password that is shorter than a certain character limit, or if it doesn't contain the at least one number or special character US 1.1.1 - Change Password SP: 1 As a user, I want to be able to change my password, so that I can keep my account secure. Acceptance Tests 1. User can click their Profile and access the Settings page 2. User is prompted to change their password 3. User cannot change their password to the same password 4. User cannot enter a password that is shorter than a certain character limit, or if it doesn't contain the at least one number or special character US 1.2 - Superuser / Admin Logging In / Out SP: 1 As a Superuser/Admin, I want to log in and log out using my UAlberta credentials, so that I can view others' datasets and predictions. Acceptance Tests 1. User is given the option to sign in using their UAlberta credentials Google Account 2. User is validated in the database to be a Superuser/Admin 3. User is given access to a separate Superuser/Admin tab 4. With this tab, the Superuser/Admin can view all datasets and select them to view predictions US 1.3 - Logged-In User Dashboard SP: 3 As a user, I want to be able to see all of my created predictors and folders, so that I can edit or use them. Acceptance Tests 1. User can navigate to their Dashboard once logged in 2. User cannot access the Dashboard if they are not logged in 3. Users can view all their created predictors and folders 4. User can select existing predictors and folders, which will provide options to edit or delete them 5. User can click on a button that lets them create a new predictor US 1.3.1 - Upload a Dataset SP: 3 As a user, I want to upload a dataset and verify it is formatted correctly, so that I can avoid errors in model training. Acceptance Tests 1. User can navigate to an \"upload dataset\" button 2. User can upload their dataset using a file upload for .csv files 3. Tests to ensure all columns / rows are formatted in accordance to the machine learning model's requirements 4. User is prompted with the detected errors, if there are any 5. User is allowed to continue if no errors are detected US 1.3.2 - Upload Formatted Datasets SP: 3 As a user, I want to upload input data as spreadsheets and .csv files, so that it's easier to upload and use. Acceptance Tests 1. User can upload .csv files using an \"upload dataset\" button 2. Website will validate and ensure the file is formatted properly US 1.3.3 - Predictor Privacy SP: 2 As a user, I want to be able to make a dataset / predictor private or public, so that I can control its access. Acceptance Tests 1. When uploading or viewing their datasets / predictors, user can select privacy 2. A logged out user can only see public datasets / predictors 3. A logged in user can only see public datasets / predictors and private predictors for which they are a selected user US 1.3.3.1 - Share Private Predictors SP: 5 As a user, I want to be able to decide which users can view my private predictor, so that I can let them use it too. Acceptance Tests 1. User can add accounts to share datasets / predictors with while creating or editing them US 1.3.3.2 - (Optional) - Manage User Permissions on Private Predictor SP: 5 As a user, I want to be able to decide which users can view my private predictor, so that I can let them use it too. Acceptance Tests 1. User can add accounts to share datasets / predictors with while creating or editing them US 1.3.4 - Create a Predictor SP: 3 As a user, I want to be able to create a predictor using a dataset i.e. train a model on my dataset, so that I can save it and view its predictions. Acceptance Tests 1. User can create a predictor after uploading a dataset 2. User can name it, add notes, toggle visibility and permissions, add it to a folder, or modify some advanced settings 3. Required fields not being filled in will result in creation failure 4. The name being the same as another existing predictor will also lead to creation failure US 1.3.5 - Edit a Predictor SP: 3 As a user, I want to be able to edit the details of my predictor (such as the notes, the dataset, and other settings), so that I can make it better. Acceptance Tests 1. User can select an existing predictor owned by them to edit 2. User can edit its name, notes, toggle visibility and permissions, add it to a folder, or modify some advanced settings 3. Required fields being removed will result in a save failure 4. User cannot select an existing predictor not owned by them to edit US 1.3.6 - Delete a Predictor SP: 1 As a user, I want to be able to delete a predictor I have made, so that I can get rid of bad or unwanted models. Acceptance Tests 1. User can select an existing predictor owned by them to delete 2. User will be taken to a confirm popup where they can cancel the delete operation or continue 3. Deletion will result in the predictor no longer being visible / removed from the database 4. Canceling deletion will lead to nothing happening 5. User cannot select an existing predictor not owned by them to delete US 1.3.7 - Pin Predictors SP: 2 As a user, I want to be able to pin predictors, so I can easily access them without needing to search them up. Acceptance Tests 1. User can select any predictor to pin 2. Pinned predictor will be added to a side panel 3. Pinned predictor can be accessed from the panel by the user 4. Pinned predictor can be can unpinned by the user - this will lead to it being removed from the side panel 5. The three universally pinned predictors will exist on top 6. The three universally pinned predictors cannot be deleted 1.3.8 (Optional) - Save My Draft Predictors SP: 3 As a user, I want to be able to save my progress when I work on creating new predictors - essentially, I can create drafts - so that I can work on them incrementally and save my progress in case of a crash / Wi-Fi cut. Acceptance Tests 1. User can start creation process 2. User can save the draft created - only needs to have the Name field filled in 3. Draft predictors are private by default - they do not show up on the Predictors tab, only on the user's Dashboard 4. Draft predictors are automatically deleted after some time 5. Draft predictors can be edited or deleted like regular predictors US 1.4.1 - Display Predictors SP: 2 As a user, I want to be able to see all public and private predictors (that I have the permissions to view or edit), so that I can decide which ones to work with. Acceptance Tests 1. User can view all public / private (if permitted) predictors on the Predictors page US 1.4.2 - Search for a Dataset / Predictor SP: 3 As a user, I want to search for a stored dataset/predictor that I have created or been granted access to, so that I can use it for my own predictions. Acceptance Tests 1. User can search for datasets / predictors using the search tab 2. User can select and view queried datasets US 1.4.3 - Filter Predictors By Public / Private SP: 1 As a user, I can filter predictors by whether they are public or private, so that it is easier to view or work with. Acceptance Tests 1. User can filter predictors by whether they are public or private 2. Checking off either one causes the other to vanish from the Predictors page 3. Checking off both leads to the default view 4. User can select and view queried datasets US 1.5 SP: 8 As a Superuser/Admin, I want to be able to view all of the public/private datasets/models, so that I can collect general statistics regarding model training and usage. Acceptance Tests 1. User can search through all datasets 2. Statistics are automatically collected by the admin panel settings 3. User can log into the admin panel and view, modify or delete entries across the website US 1.6.1 SP: 2 As a user, I want to be able to create folders, so that I can organize my predictors (and datasets) better. Acceptance Tests 1. User can create a folder once they have named it 2. User can expand or minimize a folder 3. User can rename a folder they have created US 1.6.2 - Delete Folders SP: 1 As a user, I want to be able to delete folders I have created, so that I can organize my predictors (and datasets) better. Acceptance Tests 1. User can delete a folder they have created 2. Upon deletion, the folder disappears. Its contents are not deleted 3. User cannot delete a folder not created by them US 1.6.3 - Toggle Folder Visibility SP: 5 As a user, I want to be able to set folders to public and private, so that I can control who sees my predictors. Acceptance Tests 1. User can set a folder to public or private 2. Folders have their own privacy toggle. Only becomes private if EVERY predictor in it is marked off private 3. If a folder is marked private and its contents are public, they are all private on the Predictors page, but the predictors still show up on the Predictors page 4. If a folder is marked public and most of its contents are private, only the public predictors are shown in the folder on the Predictors page US 1.6.4 - Move Predictors Between Folders SP: 5 As a user, I want to be able to drag and drop predictors into folders, so that it's easy to organize everything. Acceptance Tests 1. User can drag predictors into and out of folders 2. Visual updates and database updates should be quick and 'persist' onscreen 3. If the operation fails for any reason, an error message should flash and the predictor should go back to its original place US 1.7 - Landing Page SP: 2 As a user, I want to be able to access the landing page the moment I open the website, so I can quickly navigate anywhere. Acceptance Tests 1. User can navigate to the Landing Page US 1.8 - About Page SP: 2 As a user, I want to be able to read about the PSSP website, the research behind the tools available, and those who worked on it, so I can better understand what the purpose of the website is. Acceptance Tests 1. User can navigate to the About Page 2. User can navigate to the hyperlinked pages from the About page and view graphics 2. Interface US 2.1.1 (Optional) - Recommendation System SP: 8 As a user, I want an interface that allows me to identify an accessible dataset, a specific learning tool, and a specification of that learner\u2019s hyperparameter, so that I can save time in choosing manually. Acceptance Tests 1. User can see available learning tools on a dataset's information page 2. Interface displays information about which learning tool was used for each dataset US 2.1.2 SP: 3 As a user, I want to run this specific learner on that dataset, and save the resulting trained model securely, so that I can save my runs. Acceptance Tests 1. User can select learners for different datasets 2. System automatically saves trained models in \"versions\" 3. User can access different versions of learners on the dataset's page US 2.1.3 - Re-Train Predictors SP: 2 As a user, I want to be able to retrain predictors on subsets of features, so I can improve its predictions. Acceptance Tests 1. User can retrain predictors 2. Interface updates with a visual confirmation of training, and the success / failure US 2.1.3.1 - Search for Features SP: 2 As a user, I want to be able to search for features in a list of them, so that I can select and deselect them as needed without needing to scroll through hundreds of them. Acceptance Tests 1. User can click on the search bar and search for specific features based on name 2. If the substring matches, results are pulled up - the table size reduces to accomodate queried results US 2.1.3.2 - Select and Deselect All Features SP: 2 As a user, I want to be able to deselect and select all features at a button's click, so I don't have to do this manually. Acceptance Tests 1. User can click on the Select All button to select all features onscreen and beyond 2. User can click on the Deelect All button to deselect all features onscreen and beyond 2. If there are none onscreen due to searches, this will fail with an error message US 2.1.3.3 - Paginate Features SP: 2 As a user, I want to be able to decide how many feature entries exist on one page and navigate through the pages, so that I don't have to view hundreds of them at once. Acceptance Tests 1. User can click on the Entries Per Page box and enter / increase or decrease the number per page [using the arrows] 2. User can navigate pages using arrow buttons, and see what page they are at 2. Arrows do not exist to go beyond the last page of results or befor ethe first. US 2.2 - Implement Learning Tools SP: 5-8 As a user, I want the website to include several learning tools, each with its own set of parameters, so I can save time generating separate predictions for each metric. Acceptance Tests 1. User can select betwen different learning tools on dataset information page 2. Website displays all learning tools with their own required parameters US 2.3 SP: 8 As a user, I want the interface to show the show the (cross-validation) evaluation of the quality of this learned model, in terms of several metrics, so that I can cross-validate. Acceptance Tests 1. User can see cross-validation evaluation for learned models on a dataset information page 2. User can view a variety of metrics of the model's cross-validation 3. Running US 3.1 - Run Predictors on Unlabeled Data SP: 2 As a user, I want to run an accessible learned survival model on one or more unlabeled instances, so that I can generate predictions using my trained models. Acceptance Tests 1. User can run learned survival models on unlabeled instances using the database information page US 3.2 - Prediction Display Formats SP: 5 As a user, I want to receive predictions as ISD, like perhaps a graph of [time, probability] pairs, so that I can store them easily. Acceptance Tests 1. User can view ISD predictions on the prediction information page 2. User can view generated graphs and tweak graph settings 3. User can easily download and store graphs US 3.3 - Quality Evaluation of Predictors SP: 3 As a user, I want facilities for showing the quality of an accessible learned model, on a held-out (labelled) dataset, in terms of several metrics, so that I can understand outputted predictions easily. Acceptance Tests 1. User can view all metrics of learned models on the prediction information page US 3.4 - Dataset Metrics / Analysis SP: 3 As a user, I want #features, #instances and censor rate for each dataset, so that I can evaluate my uploaded dataset more easily. Acceptance Tests 1. User can view the features, instancse, and censor rates for each dataset on the dataset information page US 3.5 - Print Results SP: 2 As a user, I want to be able to print diagrams or predictions, so that I can store them or use them. Acceptance Tests 1. User can print diagrams or statistics using the print option 2. User can toggle diagrams or statistics for printing using toggles - they will be formatted nicely in the print screen view US 3.6 - Download Results SP: 2 As a user, I want to be able to download my results, so that I can save them on my local device. Acceptance Tests 1. User can download diagrams or statistics using the dowload option 2. User can find downloaded materials in their Downloads directory on their local device. US 3.7 - Superuser-Specific Analysis Tools SP: 5 As a Superuser/Admin, I want to be able to view and analyze others' datasets, so that I can understand general usage. Acceptance Tests 1. User can view others' dataset usage on an admin panel 2. User can view all dataset usage statistics 4. Documentation US 4.1.1 - Instructions Page SP: 1 As a user, I want instructions and a tutorial on how to use the website, so that I can easily navigate the website. Acceptance Tests 1. User will be able to watch a guided video on the \"help\" page of the website 2. User will also be able to read more detailed instructions on this help page US 4.1.2 - Hover Over Buttons / Tabs for Info SP: 2 As a user, I want to be able to see what a button does or page shows by hovering over it, so I can navigate the website and use its tools more effectively. Acceptance Tests 1. User will be able to hover over buttons 2. User will also be able to read the text on the popup that appears which will explain what the button or page does US 4.2 - Guided Tour / Demo Implementation SP: 3 As a user, I want a guided tour, so that I can get familiar using the different features and models on the website. Acceptance Tests 1. User will be prompted to start a guided tour when visiting the website for the first time on their google account 2. Various buttons and sections of the website will be highlighted 3. Text will describe what each section is for and how to use it 5. Confirmed Optional Features US 5.1 - PSSP Package Download SP: 8 As a user, I want the website to also be an add-on package for excel, SPSS, so that I may use it directly from my spreadsheets. Acceptance Tests 1. User will be able to download an excel/SPSS add-on from their respective tooling services 2. The add-on will assist in displaying information to the user US 5.2 - Handle Censored Data SP: 8 As a user, I want to an active budgeted learning for \u201cde-censoring\u201d, and dealing with left and interval-censoring, so that I may generate more precise predictions. Acceptance Tests 1. User can change specific settings regarding \"de-censoring\" 2. User can generate more precise predictions by specifying censoring information MoSCoW Must Have US 1.1 - User Logging in / Out US 1.2 - Superuser / Admin Logging In / Out US 1.3 - Logged-In User Dashboard US 1.3.1 - Upload a Dataset US 1.3.3 - Predictor Privacy US 1.3.3.1 - Share Private Predictors US 1.3.4 - Create a Predictor US 1.3.5 - Edit a Predictor US 1.3.6 - Delete a Predictor US 1.4.1 - Display Predictors US 1.4.2 - Search for a Dataset / Predictor US 1.5 - Superuser / Admin Access (Panel Set-Up) US 1.8 - About Page US 2.1.2 - Save Predictors After Runs US 2.1.3 - Re-Train Predictors US 2.1.3.1 - Search for Features US 2.1.3.2 - Select and Deselect All Features US 2.2 - Implement Learning Tools US 2.3 - Cross-Validation Evaluation of Predictor US 3.1 - Run Predictors on Unlabeled Data US 3.2 - Prediction Display Formats US 3.3 - Quality Evaluation of Predictors US 3.4 - Dataset Metrics / Analysis US 3.7 - Superuser-Specific Analysis Tools US 4.1.1 - Instructions Page US 4.1.2 - Hover Over Buttons / Tabs for Info Should Have US 1.1.1 - Change Password US 1.3.2 - Upload Formatted Datasets US 1.3.7 - Pin Predictors US 1.4.3 - Filter Predictors By Public / Private US 1.6.1 - Create Folders US 1.6.2 - Delete Folders US 1.6.3 - Toggle Folder Visibility US 1.6.4 - Move Predictors Between Folders US 1.7 - Landing Page US 2.1.3.3 - Paginate Features US 3.5 - Print Results US 3.6 - Download Results US 4.2 - Guided Tour / Demo Implementation Could Have US 1.3.8 - Save My Draft Predictors Would Like But Won't Get US 2.1.1 - Recommendation System US 5.1 - PSSP Package Download US 5.2 - Handle Censored Data Similar products ML Console Builds AI models by using uploaded dataset Secure data and predictions Used for inspiration to produce model predictions FiftyOne Identifies edge cases, outliers, duplicates and mislabeled samples Visualizes images, video, 3D in an interactive UI Used for inpiration to clean the dataset before conducting predictions Other survival analysis libraries (R survival, Python lifelines) for algorithm inspiration. Used commonly but not nearly as user-friendly for non-tech-based professionals who may want to conduct further resarch in the field Functionality may be of interest to us for the development of the backend, as stated Kaplan\u2013Meier online calculators (various web tools) as an inspiration for practical implementation techniques. Similar issue - used commonly but not nearly as user-friendly for non-tech-based professionals who may want to conduct further resarch in the field, but in the sense that it is only as insightful as the user knows it to be. May be of interest to us for the development of how to display results on the frontend Open-source products MAE-PO (SurvivalEVAL) CSD/CiPOT (MakeSurvivalCalibratedAgain) BNN-ISD Technical resources Brownfield Documentation PSSP User Guide (provided by client) NIPS paper on Cancer Research Presentations and papers on the research being supported by the project. (provided by client) Backend: Ruby on Rails + C++ / R; MySQL Frontend: React / Vite + TypeScript + Tailwind CSS + Zustand + React Router Deployment: TBD - to be communicated to us by the client at a later date","title":"Project Requirements"},{"location":"requirements/#project-requirements","text":"","title":"Project Requirements"},{"location":"requirements/#executive-summary","text":"EZ Survival Prediction is best described as a brownfield project with large patches of green. To be precise, it is based on the existing PSSP site. The current website is 7\u20138 years old, slow, and difficult to navigate, and the existing tools for learning and evaluating ISD models are slow, cumbersome and lack extensive features. Our product will let machine learning researchers and other practitioners in the relevant fields upload survival datasets, train survival models with adjustable parameters using various learning tools, evaluate the models using various metrics and run predictions on new unlabeled instances, and obtain Individual Survival Distributions (ISDs) for new instances. The system will also allow the secure storage, search, and evaluation of datasets and models. Users will be able to: Upload a survival dataset (spreadsheet format) and train a survival model with adjustable parameters. View cross-validation and other evaluation metrics for the learned model. Run the trained model on new, unlabeled instances to obtain ISD predictions (time-probability distributions). Our target users include medical researchers and clinicians, engineers, finance managers, and insurance agents who are familiar with spreadsheets but not with programming. The system is web-based, initially running in a browser (focus on Chrome). If time permits, it may also be packaged as an Excel/G-Sheet/SPSS add-on.","title":"Executive Summary"},{"location":"requirements/#project-glossary","text":"ISD - Individual Survival Distributions User - A non-logged-in user. Can view public datasets. LIU - A logged-in user. Can view all public datasets, and any private datasets they are permitted to view. Can also upload new datasets and train models. Superuser - Admin with permission to view high-level statistics across all datasets/models (public and private). Uncensored Data - Survival time that fully captures the patient\u2019s entire lifespan (i.e., complete data). Censored Data - Incomplete survival time information, representing only a lower bound of a patient\u2019s lifespan. Prevalent across datasets and an issue addressed by the client's research. KM Curve (Kaplan-Meier) - A standard survival function estimate used for comparisons.","title":"Project Glossary"},{"location":"requirements/#user-stories","text":"User stories must be prioritized using the MoSCoW method.","title":"User Stories"},{"location":"requirements/#1-user-access","text":"","title":"1. User Access"},{"location":"requirements/#us-11-user-logging-in-out","text":"SP: 3 As a user, I want to log in and log out using my Google account, so that I can save my datasets and predictions. Acceptance Tests 1. User can click the button \"Sign In With Google Account\", or alternatively enter a gmail address, followed by a password 2. User is prompted with a pop-up to choose their Google Account 3. User cannot sign up without a Google Account; the entered email is flagged if it is not a gmail account 4. User cannot enter a password that is shorter than a certain character limit, or if it doesn't contain the at least one number or special character","title":"US 1.1 - User Logging in / Out"},{"location":"requirements/#us-111-change-password","text":"SP: 1 As a user, I want to be able to change my password, so that I can keep my account secure. Acceptance Tests 1. User can click their Profile and access the Settings page 2. User is prompted to change their password 3. User cannot change their password to the same password 4. User cannot enter a password that is shorter than a certain character limit, or if it doesn't contain the at least one number or special character","title":"US 1.1.1 - Change Password"},{"location":"requirements/#us-12-superuser-admin-logging-in-out","text":"SP: 1 As a Superuser/Admin, I want to log in and log out using my UAlberta credentials, so that I can view others' datasets and predictions. Acceptance Tests 1. User is given the option to sign in using their UAlberta credentials Google Account 2. User is validated in the database to be a Superuser/Admin 3. User is given access to a separate Superuser/Admin tab 4. With this tab, the Superuser/Admin can view all datasets and select them to view predictions","title":"US 1.2 - Superuser / Admin Logging In / Out"},{"location":"requirements/#us-13-logged-in-user-dashboard","text":"SP: 3 As a user, I want to be able to see all of my created predictors and folders, so that I can edit or use them. Acceptance Tests 1. User can navigate to their Dashboard once logged in 2. User cannot access the Dashboard if they are not logged in 3. Users can view all their created predictors and folders 4. User can select existing predictors and folders, which will provide options to edit or delete them 5. User can click on a button that lets them create a new predictor","title":"US 1.3 - Logged-In User Dashboard"},{"location":"requirements/#us-131-upload-a-dataset","text":"SP: 3 As a user, I want to upload a dataset and verify it is formatted correctly, so that I can avoid errors in model training. Acceptance Tests 1. User can navigate to an \"upload dataset\" button 2. User can upload their dataset using a file upload for .csv files 3. Tests to ensure all columns / rows are formatted in accordance to the machine learning model's requirements 4. User is prompted with the detected errors, if there are any 5. User is allowed to continue if no errors are detected","title":"US 1.3.1 - Upload a Dataset"},{"location":"requirements/#us-132-upload-formatted-datasets","text":"SP: 3 As a user, I want to upload input data as spreadsheets and .csv files, so that it's easier to upload and use. Acceptance Tests 1. User can upload .csv files using an \"upload dataset\" button 2. Website will validate and ensure the file is formatted properly","title":"US 1.3.2 - Upload Formatted Datasets"},{"location":"requirements/#us-133-predictor-privacy","text":"SP: 2 As a user, I want to be able to make a dataset / predictor private or public, so that I can control its access. Acceptance Tests 1. When uploading or viewing their datasets / predictors, user can select privacy 2. A logged out user can only see public datasets / predictors 3. A logged in user can only see public datasets / predictors and private predictors for which they are a selected user","title":"US 1.3.3 - Predictor Privacy"},{"location":"requirements/#us-1331-share-private-predictors","text":"SP: 5 As a user, I want to be able to decide which users can view my private predictor, so that I can let them use it too. Acceptance Tests 1. User can add accounts to share datasets / predictors with while creating or editing them","title":"US 1.3.3.1 - Share Private Predictors"},{"location":"requirements/#us-1332-optional-manage-user-permissions-on-private-predictor","text":"SP: 5 As a user, I want to be able to decide which users can view my private predictor, so that I can let them use it too. Acceptance Tests 1. User can add accounts to share datasets / predictors with while creating or editing them","title":"US 1.3.3.2 - (Optional) - Manage User Permissions on Private Predictor"},{"location":"requirements/#us-134-create-a-predictor","text":"SP: 3 As a user, I want to be able to create a predictor using a dataset i.e. train a model on my dataset, so that I can save it and view its predictions. Acceptance Tests 1. User can create a predictor after uploading a dataset 2. User can name it, add notes, toggle visibility and permissions, add it to a folder, or modify some advanced settings 3. Required fields not being filled in will result in creation failure 4. The name being the same as another existing predictor will also lead to creation failure","title":"US 1.3.4 - Create a Predictor"},{"location":"requirements/#us-135-edit-a-predictor","text":"SP: 3 As a user, I want to be able to edit the details of my predictor (such as the notes, the dataset, and other settings), so that I can make it better. Acceptance Tests 1. User can select an existing predictor owned by them to edit 2. User can edit its name, notes, toggle visibility and permissions, add it to a folder, or modify some advanced settings 3. Required fields being removed will result in a save failure 4. User cannot select an existing predictor not owned by them to edit","title":"US 1.3.5 - Edit a Predictor"},{"location":"requirements/#us-136-delete-a-predictor","text":"SP: 1 As a user, I want to be able to delete a predictor I have made, so that I can get rid of bad or unwanted models. Acceptance Tests 1. User can select an existing predictor owned by them to delete 2. User will be taken to a confirm popup where they can cancel the delete operation or continue 3. Deletion will result in the predictor no longer being visible / removed from the database 4. Canceling deletion will lead to nothing happening 5. User cannot select an existing predictor not owned by them to delete","title":"US 1.3.6 - Delete a Predictor"},{"location":"requirements/#us-137-pin-predictors","text":"SP: 2 As a user, I want to be able to pin predictors, so I can easily access them without needing to search them up. Acceptance Tests 1. User can select any predictor to pin 2. Pinned predictor will be added to a side panel 3. Pinned predictor can be accessed from the panel by the user 4. Pinned predictor can be can unpinned by the user - this will lead to it being removed from the side panel 5. The three universally pinned predictors will exist on top 6. The three universally pinned predictors cannot be deleted","title":"US 1.3.7 - Pin Predictors"},{"location":"requirements/#138-optional-save-my-draft-predictors","text":"SP: 3 As a user, I want to be able to save my progress when I work on creating new predictors - essentially, I can create drafts - so that I can work on them incrementally and save my progress in case of a crash / Wi-Fi cut. Acceptance Tests 1. User can start creation process 2. User can save the draft created - only needs to have the Name field filled in 3. Draft predictors are private by default - they do not show up on the Predictors tab, only on the user's Dashboard 4. Draft predictors are automatically deleted after some time 5. Draft predictors can be edited or deleted like regular predictors","title":"1.3.8 (Optional) - Save My Draft Predictors"},{"location":"requirements/#us-141-display-predictors","text":"SP: 2 As a user, I want to be able to see all public and private predictors (that I have the permissions to view or edit), so that I can decide which ones to work with. Acceptance Tests 1. User can view all public / private (if permitted) predictors on the Predictors page","title":"US 1.4.1 - Display Predictors"},{"location":"requirements/#us-142-search-for-a-dataset-predictor","text":"SP: 3 As a user, I want to search for a stored dataset/predictor that I have created or been granted access to, so that I can use it for my own predictions. Acceptance Tests 1. User can search for datasets / predictors using the search tab 2. User can select and view queried datasets","title":"US 1.4.2 - Search for a Dataset / Predictor"},{"location":"requirements/#us-143-filter-predictors-by-public-private","text":"SP: 1 As a user, I can filter predictors by whether they are public or private, so that it is easier to view or work with. Acceptance Tests 1. User can filter predictors by whether they are public or private 2. Checking off either one causes the other to vanish from the Predictors page 3. Checking off both leads to the default view 4. User can select and view queried datasets","title":"US 1.4.3 - Filter Predictors By Public / Private"},{"location":"requirements/#us-15","text":"SP: 8 As a Superuser/Admin, I want to be able to view all of the public/private datasets/models, so that I can collect general statistics regarding model training and usage. Acceptance Tests 1. User can search through all datasets 2. Statistics are automatically collected by the admin panel settings 3. User can log into the admin panel and view, modify or delete entries across the website","title":"US 1.5"},{"location":"requirements/#us-161","text":"SP: 2 As a user, I want to be able to create folders, so that I can organize my predictors (and datasets) better. Acceptance Tests 1. User can create a folder once they have named it 2. User can expand or minimize a folder 3. User can rename a folder they have created","title":"US 1.6.1"},{"location":"requirements/#us-162-delete-folders","text":"SP: 1 As a user, I want to be able to delete folders I have created, so that I can organize my predictors (and datasets) better. Acceptance Tests 1. User can delete a folder they have created 2. Upon deletion, the folder disappears. Its contents are not deleted 3. User cannot delete a folder not created by them","title":"US 1.6.2 - Delete Folders"},{"location":"requirements/#us-163-toggle-folder-visibility","text":"SP: 5 As a user, I want to be able to set folders to public and private, so that I can control who sees my predictors. Acceptance Tests 1. User can set a folder to public or private 2. Folders have their own privacy toggle. Only becomes private if EVERY predictor in it is marked off private 3. If a folder is marked private and its contents are public, they are all private on the Predictors page, but the predictors still show up on the Predictors page 4. If a folder is marked public and most of its contents are private, only the public predictors are shown in the folder on the Predictors page","title":"US 1.6.3 - Toggle Folder Visibility"},{"location":"requirements/#us-164-move-predictors-between-folders","text":"SP: 5 As a user, I want to be able to drag and drop predictors into folders, so that it's easy to organize everything. Acceptance Tests 1. User can drag predictors into and out of folders 2. Visual updates and database updates should be quick and 'persist' onscreen 3. If the operation fails for any reason, an error message should flash and the predictor should go back to its original place","title":"US 1.6.4 - Move Predictors Between Folders"},{"location":"requirements/#us-17-landing-page","text":"SP: 2 As a user, I want to be able to access the landing page the moment I open the website, so I can quickly navigate anywhere. Acceptance Tests 1. User can navigate to the Landing Page","title":"US 1.7 - Landing Page"},{"location":"requirements/#us-18-about-page","text":"SP: 2 As a user, I want to be able to read about the PSSP website, the research behind the tools available, and those who worked on it, so I can better understand what the purpose of the website is. Acceptance Tests 1. User can navigate to the About Page 2. User can navigate to the hyperlinked pages from the About page and view graphics","title":"US 1.8 - About Page"},{"location":"requirements/#2-interface","text":"","title":"2. Interface"},{"location":"requirements/#us-211-optional-recommendation-system","text":"SP: 8 As a user, I want an interface that allows me to identify an accessible dataset, a specific learning tool, and a specification of that learner\u2019s hyperparameter, so that I can save time in choosing manually. Acceptance Tests 1. User can see available learning tools on a dataset's information page 2. Interface displays information about which learning tool was used for each dataset","title":"US 2.1.1 (Optional) - Recommendation System"},{"location":"requirements/#us-212","text":"SP: 3 As a user, I want to run this specific learner on that dataset, and save the resulting trained model securely, so that I can save my runs. Acceptance Tests 1. User can select learners for different datasets 2. System automatically saves trained models in \"versions\" 3. User can access different versions of learners on the dataset's page","title":"US 2.1.2"},{"location":"requirements/#us-213-re-train-predictors","text":"SP: 2 As a user, I want to be able to retrain predictors on subsets of features, so I can improve its predictions. Acceptance Tests 1. User can retrain predictors 2. Interface updates with a visual confirmation of training, and the success / failure","title":"US 2.1.3 - Re-Train Predictors"},{"location":"requirements/#us-2131-search-for-features","text":"SP: 2 As a user, I want to be able to search for features in a list of them, so that I can select and deselect them as needed without needing to scroll through hundreds of them. Acceptance Tests 1. User can click on the search bar and search for specific features based on name 2. If the substring matches, results are pulled up - the table size reduces to accomodate queried results","title":"US 2.1.3.1 - Search for Features"},{"location":"requirements/#us-2132-select-and-deselect-all-features","text":"SP: 2 As a user, I want to be able to deselect and select all features at a button's click, so I don't have to do this manually. Acceptance Tests 1. User can click on the Select All button to select all features onscreen and beyond 2. User can click on the Deelect All button to deselect all features onscreen and beyond 2. If there are none onscreen due to searches, this will fail with an error message","title":"US 2.1.3.2 - Select and Deselect All Features"},{"location":"requirements/#us-2133-paginate-features","text":"SP: 2 As a user, I want to be able to decide how many feature entries exist on one page and navigate through the pages, so that I don't have to view hundreds of them at once. Acceptance Tests 1. User can click on the Entries Per Page box and enter / increase or decrease the number per page [using the arrows] 2. User can navigate pages using arrow buttons, and see what page they are at 2. Arrows do not exist to go beyond the last page of results or befor ethe first.","title":"US 2.1.3.3 - Paginate Features"},{"location":"requirements/#us-22-implement-learning-tools","text":"SP: 5-8 As a user, I want the website to include several learning tools, each with its own set of parameters, so I can save time generating separate predictions for each metric. Acceptance Tests 1. User can select betwen different learning tools on dataset information page 2. Website displays all learning tools with their own required parameters","title":"US 2.2 - Implement Learning Tools"},{"location":"requirements/#us-23","text":"SP: 8 As a user, I want the interface to show the show the (cross-validation) evaluation of the quality of this learned model, in terms of several metrics, so that I can cross-validate. Acceptance Tests 1. User can see cross-validation evaluation for learned models on a dataset information page 2. User can view a variety of metrics of the model's cross-validation","title":"US 2.3"},{"location":"requirements/#3-running","text":"","title":"3. Running"},{"location":"requirements/#us-31-run-predictors-on-unlabeled-data","text":"SP: 2 As a user, I want to run an accessible learned survival model on one or more unlabeled instances, so that I can generate predictions using my trained models. Acceptance Tests 1. User can run learned survival models on unlabeled instances using the database information page","title":"US 3.1 - Run Predictors on Unlabeled Data"},{"location":"requirements/#us-32-prediction-display-formats","text":"SP: 5 As a user, I want to receive predictions as ISD, like perhaps a graph of [time, probability] pairs, so that I can store them easily. Acceptance Tests 1. User can view ISD predictions on the prediction information page 2. User can view generated graphs and tweak graph settings 3. User can easily download and store graphs","title":"US 3.2 - Prediction Display Formats"},{"location":"requirements/#us-33-quality-evaluation-of-predictors","text":"SP: 3 As a user, I want facilities for showing the quality of an accessible learned model, on a held-out (labelled) dataset, in terms of several metrics, so that I can understand outputted predictions easily. Acceptance Tests 1. User can view all metrics of learned models on the prediction information page","title":"US 3.3 - Quality Evaluation of Predictors"},{"location":"requirements/#us-34-dataset-metrics-analysis","text":"SP: 3 As a user, I want #features, #instances and censor rate for each dataset, so that I can evaluate my uploaded dataset more easily. Acceptance Tests 1. User can view the features, instancse, and censor rates for each dataset on the dataset information page","title":"US 3.4 - Dataset Metrics / Analysis"},{"location":"requirements/#us-35-print-results","text":"SP: 2 As a user, I want to be able to print diagrams or predictions, so that I can store them or use them. Acceptance Tests 1. User can print diagrams or statistics using the print option 2. User can toggle diagrams or statistics for printing using toggles - they will be formatted nicely in the print screen view","title":"US 3.5 - Print Results"},{"location":"requirements/#us-36-download-results","text":"SP: 2 As a user, I want to be able to download my results, so that I can save them on my local device. Acceptance Tests 1. User can download diagrams or statistics using the dowload option 2. User can find downloaded materials in their Downloads directory on their local device.","title":"US 3.6 - Download Results"},{"location":"requirements/#us-37-superuser-specific-analysis-tools","text":"SP: 5 As a Superuser/Admin, I want to be able to view and analyze others' datasets, so that I can understand general usage. Acceptance Tests 1. User can view others' dataset usage on an admin panel 2. User can view all dataset usage statistics","title":"US 3.7 - Superuser-Specific Analysis Tools"},{"location":"requirements/#4-documentation","text":"","title":"4. Documentation"},{"location":"requirements/#us-411-instructions-page","text":"SP: 1 As a user, I want instructions and a tutorial on how to use the website, so that I can easily navigate the website. Acceptance Tests 1. User will be able to watch a guided video on the \"help\" page of the website 2. User will also be able to read more detailed instructions on this help page","title":"US 4.1.1 - Instructions Page"},{"location":"requirements/#us-412-hover-over-buttons-tabs-for-info","text":"SP: 2 As a user, I want to be able to see what a button does or page shows by hovering over it, so I can navigate the website and use its tools more effectively. Acceptance Tests 1. User will be able to hover over buttons 2. User will also be able to read the text on the popup that appears which will explain what the button or page does","title":"US 4.1.2 - Hover Over Buttons / Tabs for Info"},{"location":"requirements/#us-42-guided-tour-demo-implementation","text":"SP: 3 As a user, I want a guided tour, so that I can get familiar using the different features and models on the website. Acceptance Tests 1. User will be prompted to start a guided tour when visiting the website for the first time on their google account 2. Various buttons and sections of the website will be highlighted 3. Text will describe what each section is for and how to use it","title":"US 4.2 - Guided Tour / Demo Implementation"},{"location":"requirements/#5-confirmed-optional-features","text":"","title":"5. Confirmed Optional Features"},{"location":"requirements/#us-51-pssp-package-download","text":"SP: 8 As a user, I want the website to also be an add-on package for excel, SPSS, so that I may use it directly from my spreadsheets. Acceptance Tests 1. User will be able to download an excel/SPSS add-on from their respective tooling services 2. The add-on will assist in displaying information to the user","title":"US 5.1 - PSSP Package Download"},{"location":"requirements/#us-52-handle-censored-data","text":"SP: 8 As a user, I want to an active budgeted learning for \u201cde-censoring\u201d, and dealing with left and interval-censoring, so that I may generate more precise predictions. Acceptance Tests 1. User can change specific settings regarding \"de-censoring\" 2. User can generate more precise predictions by specifying censoring information","title":"US 5.2 - Handle Censored Data"},{"location":"requirements/#moscow","text":"","title":"MoSCoW"},{"location":"requirements/#must-have","text":"US 1.1 - User Logging in / Out US 1.2 - Superuser / Admin Logging In / Out US 1.3 - Logged-In User Dashboard US 1.3.1 - Upload a Dataset US 1.3.3 - Predictor Privacy US 1.3.3.1 - Share Private Predictors US 1.3.4 - Create a Predictor US 1.3.5 - Edit a Predictor US 1.3.6 - Delete a Predictor US 1.4.1 - Display Predictors US 1.4.2 - Search for a Dataset / Predictor US 1.5 - Superuser / Admin Access (Panel Set-Up) US 1.8 - About Page US 2.1.2 - Save Predictors After Runs US 2.1.3 - Re-Train Predictors US 2.1.3.1 - Search for Features US 2.1.3.2 - Select and Deselect All Features US 2.2 - Implement Learning Tools US 2.3 - Cross-Validation Evaluation of Predictor US 3.1 - Run Predictors on Unlabeled Data US 3.2 - Prediction Display Formats US 3.3 - Quality Evaluation of Predictors US 3.4 - Dataset Metrics / Analysis US 3.7 - Superuser-Specific Analysis Tools US 4.1.1 - Instructions Page US 4.1.2 - Hover Over Buttons / Tabs for Info","title":"Must Have"},{"location":"requirements/#should-have","text":"US 1.1.1 - Change Password US 1.3.2 - Upload Formatted Datasets US 1.3.7 - Pin Predictors US 1.4.3 - Filter Predictors By Public / Private US 1.6.1 - Create Folders US 1.6.2 - Delete Folders US 1.6.3 - Toggle Folder Visibility US 1.6.4 - Move Predictors Between Folders US 1.7 - Landing Page US 2.1.3.3 - Paginate Features US 3.5 - Print Results US 3.6 - Download Results US 4.2 - Guided Tour / Demo Implementation","title":"Should Have"},{"location":"requirements/#could-have","text":"US 1.3.8 - Save My Draft Predictors","title":"Could Have"},{"location":"requirements/#would-like-but-wont-get","text":"US 2.1.1 - Recommendation System US 5.1 - PSSP Package Download US 5.2 - Handle Censored Data","title":"Would Like But Won't Get"},{"location":"requirements/#similar-products","text":"ML Console Builds AI models by using uploaded dataset Secure data and predictions Used for inspiration to produce model predictions FiftyOne Identifies edge cases, outliers, duplicates and mislabeled samples Visualizes images, video, 3D in an interactive UI Used for inpiration to clean the dataset before conducting predictions Other survival analysis libraries (R survival, Python lifelines) for algorithm inspiration. Used commonly but not nearly as user-friendly for non-tech-based professionals who may want to conduct further resarch in the field Functionality may be of interest to us for the development of the backend, as stated Kaplan\u2013Meier online calculators (various web tools) as an inspiration for practical implementation techniques. Similar issue - used commonly but not nearly as user-friendly for non-tech-based professionals who may want to conduct further resarch in the field, but in the sense that it is only as insightful as the user knows it to be. May be of interest to us for the development of how to display results on the frontend","title":"Similar products"},{"location":"requirements/#open-source-products","text":"MAE-PO (SurvivalEVAL) CSD/CiPOT (MakeSurvivalCalibratedAgain) BNN-ISD","title":"Open-source products"},{"location":"requirements/#technical-resources","text":"","title":"Technical resources"},{"location":"requirements/#brownfield-documentation","text":"PSSP User Guide (provided by client) NIPS paper on Cancer Research Presentations and papers on the research being supported by the project. (provided by client)","title":"Brownfield Documentation"},{"location":"requirements/#backend","text":"Ruby on Rails + C++ / R; MySQL","title":"Backend:"},{"location":"requirements/#frontend","text":"React / Vite + TypeScript + Tailwind CSS + Zustand + React Router","title":"Frontend:"},{"location":"requirements/#deployment","text":"TBD - to be communicated to us by the client at a later date","title":"Deployment:"},{"location":"teamwork/","text":"Teamwork This section includes three parts: 1. Team Canvas 2. Scrum Roles We discussed this, as well as what the roles entailed, and decided that the best approach was to start with the two most forthcoming members, and test it out. If any members feel inclined to lead, we will adjust accordingly (and shift to a cyclical strcture for the scrum roles). For the foreseeable future, however, we have: Scrum Master : Yaatheshini Ashok Product Owner : Selena Chainani 3. Belbin Team Roles The Belbim Team Roles appear to be quite crucial - largely because they helped us clarify what each of us are good at, comfortable with, and willing to do. It opened up a larger conversation regarding what we all truly do beyond the class, as well as our goals, and this was imperative in deciding the progression of the project and our relations with each other. We found that the Belbin roles were somewhat applicable - more generally, they served as guidelines fthat we could utilize to communicate, if that makes sense. Team Member Preferred Roles Manageable Roles Least Preferred Roles Advi Islam SH, TW, IMP CF, RI , CO ME, PL, SP Alex Ho RI, SP, IMP, CF, TW ME, PL, CO SH Excel Ojeifo PL, CF, IMP SP, ME, RI CO, TW, SH Hoang Nguyen PL, IMP, SP, SH, CF TW, ME RI, CO Selena Chainani PL, CO, CF, IMP TW, ME, SH, SP RI Shahmeer Rahman ME, CF, TW PL, IMP, CO SP, SH, RI Yaatheshini Ashok Kumar CF, CO, SH, TW IMP, ME, PL SP, RI Thinking Roles PL (Plant) Tends to be highly creative and good at solving problems in unconventional ways. Excel Ojeifo (Preferred) Hoang Nguyen (Preferred) Selena Chainani (Preferred) Shahmeer Rahman (Manageable) Yaatheshini Ashok Kumar (Manageable) ME (Monitor Evaluator) Provides a logical eye, making impartial judgements where required and weighs up the team's options in a dispassionate way. Shahmeer Rahman (Preferred) Alex Ho (Manageable) Excel Ojeifo (Manageable) Hoang Nguyen (Manageable) Selena Chainani (Manageable) Yaatheshini Ashok Kumar (Manageable) SP (Specialist) Brings in-depth knowledge of a key area to the team. Alex Ho (Preferred) Hoang Nguyen (Preferred) Excel Ojeifo (Manageable) Selena Chainani (Manageable) Action Roles SH (Shaper) Provides the necessary drive to ensure that the team keeps moving and does not lose focus or momentum. Advi Islam (Preferred) Hoang Nguyen (Preferred) Yaatheshini Ashok Kumar (Preferred) Selena Chainani (Manageable) IMP (Implementer) Needed to plan a workable strategy and carry it out as efficiently as possible. Advi Islam (Preferred) Alex Ho (Preferred) Excel Ojeifo (Preferred) Hoang Nguyen (Preferred) Selena Chainani (Preferred) Shahmeer Rahman (Manageable) Yaatheshini Ashok Kumar (Manageable) CF (Completer Finisher) Most effectively used at the end of tasks to polish and scrutinise the work for errors, subjecting it to the highest standards of quality control. Alex Ho (Preferred) Excel Ojeifo (Preferred) Hoang Nguyen (Preferred) Selena Chainani (Preferred) Shahmeer Rahman (Preferred) Yaatheshini Ashok Kumar (Preferred) Advi Islam (Manageable) People Roles RI (Resource Investigator) Uses their inquisitive nature to find ideas to bring back to the team. Alex Ho (Preferred) Advi Islam (Manageable) Excel Ojeifo (Manageable) TW (Teamworker) Helps the team to gel, using their versatility to identify the work required and complete it on behalf of the team. Advi Islam (Preferred) Alex Ho (Preferred) Shahmeer Rahman (Preferred) Yaatheshini Ashok Kumar (Preferred) Hoang Nguyen (Manageable) Selena Chainani (Manageable) CO (Co-ordinator) Needed to focus on the team's objectives, draw out team members and delegate work appropriately. Selena Chainani (Preferred) Yaatheshini Ashok Kumar (Preferred) Advi Islam (Manageable) Alex Ho (Manageable) Shahmeer Rahman (Manageable)","title":"Teamwork"},{"location":"teamwork/#teamwork","text":"This section includes three parts:","title":"Teamwork"},{"location":"teamwork/#1-team-canvas","text":"","title":"1. Team Canvas"},{"location":"teamwork/#2-scrum-roles","text":"We discussed this, as well as what the roles entailed, and decided that the best approach was to start with the two most forthcoming members, and test it out. If any members feel inclined to lead, we will adjust accordingly (and shift to a cyclical strcture for the scrum roles). For the foreseeable future, however, we have: Scrum Master : Yaatheshini Ashok Product Owner : Selena Chainani","title":"2. Scrum Roles"},{"location":"teamwork/#3-belbin-team-roles","text":"The Belbim Team Roles appear to be quite crucial - largely because they helped us clarify what each of us are good at, comfortable with, and willing to do. It opened up a larger conversation regarding what we all truly do beyond the class, as well as our goals, and this was imperative in deciding the progression of the project and our relations with each other. We found that the Belbin roles were somewhat applicable - more generally, they served as guidelines fthat we could utilize to communicate, if that makes sense. Team Member Preferred Roles Manageable Roles Least Preferred Roles Advi Islam SH, TW, IMP CF, RI , CO ME, PL, SP Alex Ho RI, SP, IMP, CF, TW ME, PL, CO SH Excel Ojeifo PL, CF, IMP SP, ME, RI CO, TW, SH Hoang Nguyen PL, IMP, SP, SH, CF TW, ME RI, CO Selena Chainani PL, CO, CF, IMP TW, ME, SH, SP RI Shahmeer Rahman ME, CF, TW PL, IMP, CO SP, SH, RI Yaatheshini Ashok Kumar CF, CO, SH, TW IMP, ME, PL SP, RI","title":"3. Belbin Team Roles"},{"location":"teamwork/#thinking-roles","text":"","title":"Thinking Roles"},{"location":"teamwork/#pl-plant","text":"Tends to be highly creative and good at solving problems in unconventional ways. Excel Ojeifo (Preferred) Hoang Nguyen (Preferred) Selena Chainani (Preferred) Shahmeer Rahman (Manageable) Yaatheshini Ashok Kumar (Manageable)","title":"PL (Plant)"},{"location":"teamwork/#me-monitor-evaluator","text":"Provides a logical eye, making impartial judgements where required and weighs up the team's options in a dispassionate way. Shahmeer Rahman (Preferred) Alex Ho (Manageable) Excel Ojeifo (Manageable) Hoang Nguyen (Manageable) Selena Chainani (Manageable) Yaatheshini Ashok Kumar (Manageable)","title":"ME (Monitor Evaluator)"},{"location":"teamwork/#sp-specialist","text":"Brings in-depth knowledge of a key area to the team. Alex Ho (Preferred) Hoang Nguyen (Preferred) Excel Ojeifo (Manageable) Selena Chainani (Manageable)","title":"SP (Specialist)"},{"location":"teamwork/#action-roles","text":"","title":"Action Roles"},{"location":"teamwork/#sh-shaper","text":"Provides the necessary drive to ensure that the team keeps moving and does not lose focus or momentum. Advi Islam (Preferred) Hoang Nguyen (Preferred) Yaatheshini Ashok Kumar (Preferred) Selena Chainani (Manageable)","title":"SH (Shaper)"},{"location":"teamwork/#imp-implementer","text":"Needed to plan a workable strategy and carry it out as efficiently as possible. Advi Islam (Preferred) Alex Ho (Preferred) Excel Ojeifo (Preferred) Hoang Nguyen (Preferred) Selena Chainani (Preferred) Shahmeer Rahman (Manageable) Yaatheshini Ashok Kumar (Manageable)","title":"IMP (Implementer)"},{"location":"teamwork/#cf-completer-finisher","text":"Most effectively used at the end of tasks to polish and scrutinise the work for errors, subjecting it to the highest standards of quality control. Alex Ho (Preferred) Excel Ojeifo (Preferred) Hoang Nguyen (Preferred) Selena Chainani (Preferred) Shahmeer Rahman (Preferred) Yaatheshini Ashok Kumar (Preferred) Advi Islam (Manageable)","title":"CF (Completer Finisher)"},{"location":"teamwork/#people-roles","text":"","title":"People Roles"},{"location":"teamwork/#ri-resource-investigator","text":"Uses their inquisitive nature to find ideas to bring back to the team. Alex Ho (Preferred) Advi Islam (Manageable) Excel Ojeifo (Manageable)","title":"RI (Resource Investigator)"},{"location":"teamwork/#tw-teamworker","text":"Helps the team to gel, using their versatility to identify the work required and complete it on behalf of the team. Advi Islam (Preferred) Alex Ho (Preferred) Shahmeer Rahman (Preferred) Yaatheshini Ashok Kumar (Preferred) Hoang Nguyen (Manageable) Selena Chainani (Manageable)","title":"TW (Teamworker)"},{"location":"teamwork/#co-co-ordinator","text":"Needed to focus on the team's objectives, draw out team members and delegate work appropriately. Selena Chainani (Preferred) Yaatheshini Ashok Kumar (Preferred) Advi Islam (Manageable) Alex Ho (Manageable) Shahmeer Rahman (Manageable)","title":"CO (Co-ordinator)"}]}